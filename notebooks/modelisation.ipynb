{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('/Users/guimb/Documents/Data Scientest/rakuten/data/X_train.csv', sep=',', index_col='Unnamed: 0')\n",
    "y_train = pd.read_csv('/Users/guimb/Documents/Data Scientest/rakuten/data/Y_train.csv', sep=',', index_col='Unnamed: 0')\n",
    "df = x_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \\\n",
       "0                                                NaN  3804725264  1263597046   \n",
       "1                                                NaN   436067568  1008141237   \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978   \n",
       "3                                                NaN    50418756   457047496   \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786   \n",
       "\n",
       "   prdtypecode  \n",
       "0           10  \n",
       "1         2280  \n",
       "2           50  \n",
       "3         1280  \n",
       "4         2705  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"].fillna(df[\"designation\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les colonnes \"désignation\" et \"description\"\n",
    "df[\"description\"] = df[\"designation\"] + \" \" + df[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['designation', 'description', 'productid', 'imageid', 'prdtypecode'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# Fonction pour détecter la langue d'une description\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "# Appliquer la détection de langue à la colonne \"description\" et créer une nouvelle colonne \"langue\"\n",
    "df[\"langue\"] = df[\"description\"].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['designation', 'description', 'productid', 'imageid', 'prdtypecode',\n",
       "       'langue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'fr' 'en' 'ro' 'nl' 'ca' 'es' 'pt' 'it' 'no' 'tl' 'id' 'af' 'so'\n",
      " 'et' 'da' 'sv' 'fi' 'sw' 'cy' 'vi' 'sl' 'pl' 'hr' 'hu' 'sk' 'lt' 'tr'\n",
      " 'lv' 'cs' 'sq']\n"
     ]
    }
   ],
   "source": [
    "# Appliquer la détection de langue à la colonne \"description\" et créer une nouvelle colonne \"langue\"\n",
    "langues = df[\"langue\"].unique()\n",
    "print(langues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'httpcore' has no attribute 'SyncHTTPTransport'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/guimb/Documents/Data Scientest/rakuten/AUG23_Rakuten/notebooks/modelisation_guillaume.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/AUG23_Rakuten/notebooks/modelisation_guillaume.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/AUG23_Rakuten/notebooks/modelisation_guillaume.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogletrans\u001b[39;00m \u001b[39mimport\u001b[39;00m Translator\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/AUG23_Rakuten/notebooks/modelisation_guillaume.ipynb#X65sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate_to_french\u001b[39m(row):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/AUG23_Rakuten/notebooks/modelisation_guillaume.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     translator \u001b[39m=\u001b[39m Translator()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/googletrans/__init__.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m __all__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTranslator\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3.0.0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogletrans\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m Translator\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogletrans\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m LANGCODES, LANGUAGES  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/googletrans/client.py:25\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogletrans\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Translated, Detected\n\u001b[1;32m     22\u001b[0m EXCLUDES \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39men\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mca\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mTranslator\u001b[39;49;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m\"\"\"Google Translate ajax API implementation class\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[39m    You have to create an instance of Translator to use this API\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m    :type raise_exception: boolean\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, service_urls\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, user_agent\u001b[39m=\u001b[39;49mDEFAULT_USER_AGENT,\n\u001b[1;32m     54\u001b[0m                  raise_exception\u001b[39m=\u001b[39;49mDEFAULT_RAISE_EXCEPTION,\n\u001b[1;32m     55\u001b[0m                  proxies: typing\u001b[39m.\u001b[39;49mDict[\u001b[39mstr\u001b[39;49m, httpcore\u001b[39m.\u001b[39;49mSyncHTTPTransport] \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m, timeout: Timeout \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/googletrans/client.py:55\u001b[0m, in \u001b[0;36mTranslator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTranslator\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Google Translate ajax API implementation class\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[39m    You have to create an instance of Translator to use this API\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m    :type raise_exception: boolean\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, service_urls\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_agent\u001b[39m=\u001b[39mDEFAULT_USER_AGENT,\n\u001b[1;32m     54\u001b[0m                  raise_exception\u001b[39m=\u001b[39mDEFAULT_RAISE_EXCEPTION,\n\u001b[0;32m---> 55\u001b[0m                  proxies: typing\u001b[39m.\u001b[39mDict[\u001b[39mstr\u001b[39m, httpcore\u001b[39m.\u001b[39;49mSyncHTTPTransport] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, timeout: Timeout \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     57\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m httpx\u001b[39m.\u001b[39mClient()\n\u001b[1;32m     58\u001b[0m         \u001b[39mif\u001b[39;00m proxies \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# pragma: nocover\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'httpcore' has no attribute 'SyncHTTPTransport'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from googletrans import Translator\n",
    "\n",
    "\n",
    "def translate_to_french(row):\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        for col in [\"designation\", \"description\"]:\n",
    "            if row[\"langue\"] != \"fr\":\n",
    "                row[col] = translator.translate(row[col], src=\"auto\", dest=\"fr\").text\n",
    "        return row\n",
    "    except:\n",
    "        return row\n",
    "\n",
    "\n",
    "# Appliquer la traduction en utilisant tqdm pour afficher la progression\n",
    "tqdm.pandas(desc=\"Traduction en cours\")\n",
    "\n",
    "# Apply the translation function to each row\n",
    "df = df.progress_apply(translate_to_french, axis=1)\n",
    "\n",
    "# Now df contains the translated text in columns 'designation' and 'description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'langue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'langue'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/guimb/Documents/Data Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Appliquer la détection de langue à la colonne \"description\" et créer une nouvelle colonne \"langue\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m langues \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mlangue\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(langues)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'langue'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Appliquer la détection de langue à la colonne \"description\" et créer une nouvelle colonne \"langue\"\n",
    "langues = df[\"langue\"].unique()\n",
    "print(langues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir le texte en minuscules\n",
    "df[\"description\"] = df[\"description\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimez les doublons de la colonne 'description'\n",
    "df.drop_duplicates(subset=[\"description\"], inplace=True)\n",
    "\n",
    "# Réindexez le DataFrame\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan '<br>' '<span class=\"vga_style2\">' '<b>' '</b>' '<strong>'\n",
      " '</strong>' '<ul>' '<li>' '</li>' '</ul>' '<br />' '<p>' '</p>' '<i>'\n",
      " '</i>' '<span id=\"result_box\" lang=\"en\" tabindex=\"-1\">'\n",
      " '<span class=\"hps\">' '</span>' '<span class=\"hps atn\">' '<span>'\n",
      " '<p align=&quot;justify&quot;>' '<h4>' '</h4>'\n",
      " '<iframe allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/iahzt0bebhw\" width=\"560\">'\n",
      " '</iframe>' '<div>' '</div>' '<div class=\"rakuten_rich_content\" >' '<h2>'\n",
      " '</h2>' '<br/>' '<u>' '</u>' '<html>' '</html>' '<h3>' '</h3>'\n",
      " '<img src=\"https://www.deuba24online.de/media/magnalister/products/500px/a_de_102199g1.jpg\" style=\"border:0;\" alt=\"\" title=\"\" />'\n",
      " '<img src=\"https://www.deuba24online.de/media/magnalister/products/500px/de_102199d_1_2.jpg\" style=\"border:0;\" alt=\"\" title=\"\" />'\n",
      " '<img src=\"https://www.deuba24online.de/media/magnalister/products/500px/de_102199d_2_2.jpg\" style=\"border:0;\" alt=\"\" title=\"\" />'\n",
      " '<font size=&quot;3&quot;>' '</font>' '<em>' '</em>' '<ol>' '</ol>'\n",
      " '<p class=\"detail-txt-item\">' '<span style=\"text-decoration:underline;\">'\n",
      " '< 54 dba</li>' '< 42 dba</li>' '< 33 dba</li>'\n",
      " '<object width=\"850\" height=\"1000\" type=\"text/html\" data=\"http://194.185.40.5/area_informativa/ricerca_schede/schedehwserviziodati.asp?idazienda=1&codice=0f3ac2\">'\n",
      " '</object>'\n",
      " '<object width=\"850\" height=\"1000\" type=\"text/html\" data=\"http://194.185.40.5/area_informativa/ricerca_schede/schedehwserviziodati.asp?idazienda=1&codice=56922\">'\n",
      " \"<hr align='center' width='100%' size='1'>\"\n",
      " '<a href=&quot;http://lepetitlitteraire.fr&quot;>' '</a>'\n",
      " '<p style=\"text-align: justify;\">' '< br / >' '</br>'\n",
      " '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/f00brur5xpq\" frameborder=\"0\">'\n",
      " '<br style=\"font-size: 10.0pt; mso-bidi-font-size: 12.0pt; font-family: arial; color: #1e3479; mso-fareast-language: fr;\" />'\n",
      " '<p class=\"bold\">' '<li class=\"detail-txt-item\">'\n",
      " '<iframe height=\"315\" src=\"https://www.youtube.com/embed/ubfcfoummy8\" frameborder=\"0&quot;\" width=\"560\" allow=\"autoplay; encrypted-media\" allowfullscreen>'\n",
      " '<sub>' '</sub>' '<sup>' '</sup>' '<span style=\"font-size: 14px;\">'\n",
      " '<span style=\"font-size: 14px; line-height: 1.5em;\">'\n",
      " '<span style=\"line-height: 1.2;\">'\n",
      " '<strong style=\"margin: 0px; padding: 0px; border-spacing: 0px; border-collapse: collapse;\">'\n",
      " '<li style=\"margin: 0px 0px 0px 20px; padding: 0px; border-spacing: 0px; border-collapse: collapse; list-style: square;\">'\n",
      " \"<span style='text-decoration:underline;'>\" '< li>' \"<p align='center'>\"\n",
      " '<a href=&quot;http://www.lepetitlitteraire.fr/&quot;>'\n",
      " '<a href=http://garcon-lejeu.com/videoweb4.wmv>'\n",
      " '<a href=http://garcon-lejeu.com/partie.htm>' '<li >' '<br\\xa0/>'\n",
      " '<strong style=\"font-size: 16px;\">'\n",
      " '<span style=\"font-family: arialhelveticasans-serif;\">'\n",
      " '<a href=&quot;http://www.pol-editeur.fr/catalogue/fichelivre.asp?clef=362&quot; rel=&quot;external&quot;>'\n",
      " '<a href=&quot;http://www.editions-verdier.fr/v3/auteur-darley.html&quot; rel=&quot;external&quot;>'\n",
      " '<a href=&quot;http://journaledarley.blogspot.com/&quot; rel=&quot;external&quot;>'\n",
      " '<p align=center style=font-size:22px;>'\n",
      " '<iframe width=560 height=315 src=https://www.youtube-nocookie.com/embed/fuwbuzv1mwo?rel=0 frameborder=0 allowfullscreen>'\n",
      " '<p<p>' '<font face=arial verdana size=2>'\n",
      " '<div class=msonormal style=margin: 0cm 0cm 0pt>'\n",
      " '<div class=\"box-collateral-content\">' '<div class=\"std\">'\n",
      " '<p class=\"std\">' '<span style=\"font-size: large;\">'\n",
      " '<span style=\"color: #55c426;\">' '<span class=\"r-iw7pv_gdb57g\">'\n",
      " '<span style=\"color: #347ccb;\">' '<span style=\"font-size: small;\">'\n",
      " '<span style=\"font-size: large; color: #55c426;\">'\n",
      " '<img style=\"float: left;\" title=\"fabriqu&eacute; en france\" src=\"http://www.piscine-distribution.com/media/wysiwyg/fabriqu_-en-france.jpg\" alt=\"fabriqu&eacute; en france\" width=\"140\" height=\"140\" />'\n",
      " '<p style=\"text-align: left;\">' '<li style=\"text-align: left;\">'\n",
      " '<span style=\"font-size: medium;\">'\n",
      " '<span style=\"font-size: large; color: #347ccb;\">'\n",
      " '<img title=\"sryh\" src=\"{{media url=\"wysiwyg/fleur-d-oranger.jpg\"}}\" alt=\"dsgh\" width=\"95\" height=\"103\" />'\n",
      " '<img title=\"velours de spa lavandin\" src=\"{{media url=\"wysiwyg/lavandin.jpg\"}}\" alt=\"velours de spa lavandin\" width=\"105\" height=\"99\" />'\n",
      " '<img title=\"velours de spa luxe\" src=\"{{media url=\"wysiwyg/luxe.jpg\"}}\" alt=\"velours de spa luxe\" width=\"115\" height=\"125\" />'\n",
      " '<img title=\"velours de spa eucalyptus menthe\" src=\"{{media url=\"wysiwyg/eucalyptusfeuillesmenthe__0.jpg\"}}\" alt=\"velours de spa eucalyptus menthe\" width=\"104\" height=\"122\" />'\n",
      " '<img title=\"velours de spa asie\" src=\"{{media url=\"wysiwyg/asie.jpg\"}}\" alt=\"velours de spa asie\" width=\"98\" height=\"109\" />'\n",
      " '<img title=\"velours de spa pin\" src=\"{{media url=\"wysiwyg/pin.jpg\"}}\" alt=\"velours de spa pin\" width=\"84\" height=\"102\" />'\n",
      " '<img style=\"vertical-align: middle;\" title=\"velours de spa eucalyptus\" src=\"{{media url=\"wysiwyg/eucalyptus_1.jpg\"}}\" alt=\"velours de spa eucalyptus\" width=\"99\" height=\"94\" />'\n",
      " '<p style=\"text-align: center;\">'\n",
      " '<span style=\"font-family: \\'comic sans ms\\' sans-serif; font-size: 14pt;\">'\n",
      " '< 55 dba</li>' '< 44 dba</li>' '< 34 dba</li>' '<table>' '<tbody>'\n",
      " '<tr>' '<td>' '</td>' '</tr>' '</tbody>' '</table>'\n",
      " '<span id=\"result_box\" lang=\"en\">' '< 0.5 s </br>' '< 1 s </br>'\n",
      " '<div class=\"content_text\">'\n",
      " '<br style=\"line-height: 20.8px; font-style: italic;\" />'\n",
      " '<span style=\"line-height: 20.8px; font-style: italic;\">'\n",
      " '<p align= &quot;justify&quot;>'\n",
      " '<iframe width=560 height=315 src=https://www.youtube-nocookie.com/embed/p4nx7bpulq0?rel=0 frameborder=0 allowfullscreen>'\n",
      " '<div class=\"content\">' '<a href=\"626\" \"\">'\n",
      " '<p style=\"text-align: left;\" data-mce-style=\"text-align: left;\">'\n",
      " '<li class=\"feature_32\" title=\"langue(s)\">' '<span class=\"icon\">'\n",
      " '<li class=\"feature_34\" title=\"age\">'\n",
      " '<li class=\"feature_37\" title=\"dur&eacute;e d&#039;une partie\">'\n",
      " '<li class=\"feature_33\" title=\"nombre de joueurs\">'\n",
      " '<div class=\"variationcharacteristics js_characteristics detailtable\" id=\"characteristics\">'\n",
      " '</annomeldung>' '<p style=text-align: justify>'\n",
      " '<iframe src=//www.dailymotion.com/embed/video/x17tie5 width=480 height=270 frameborder=0 allowfullscreen=allowfullscreen>'\n",
      " '<a href=https://www.dailymotion.com/video/x17tie5_videoregle-334-les-trois-petits-cochons_lifestyle target=_blank>'\n",
      " '<a href=https://www.dailymotion.com/yahndrev target=_blank>' '<b/>'\n",
      " '<li style=\"text-align: justify;\">' '<span style=\"font-style: italic;\">'\n",
      " '<br style=\"font-style: italic;\" />'\n",
      " '<iframe height=\"315\" src=\"https://www.youtube.com/embed/8edntwu6nqc\" frameborder=\"0&quot;\" width=\"560\" allow=\"autoplay; encrypted-media\" allowfullscreen>'\n",
      " '<span lang=\"en\">' '< br />' '<br / >'\n",
      " '<span style=&quot;font-style: italic;&quot;>'\n",
      " '<p data-version=&quot;1.1&quot;>' '<div id=\"gt-src-tools\">'\n",
      " '<div id=\"tts_button\">' '<div id=\"gt-res-content\">'\n",
      " '<div dir=\"ltr\" style=\"zoom:1\">' '<pre>' '</pre>' '<div class=\"rte\">'\n",
      " '<span data-mce-style=\"font-size: small;\">' '<th>' '</th>'\n",
      " '<p style=text-align: left>'\n",
      " '<span style=\"font-size: x-large; color: #55c426;\">'\n",
      " '<img style=\"display: block; margin-left: auto; margin-right: auto;\" title=\"aromath&eacute;rapie eucalyptus menthe\" src=\"{{media url=\"wysiwyg/eucalyptusfeuillesmenthe__0.jpg\"}}\" alt=\"aromath&eacute;rapie eucalyptus menthe\" width=\"152\" height=\"154\" />'\n",
      " '<span style=\"float: left;\">'\n",
      " '<img style=\"display: block; margin-left: auto; margin-right: auto;\" title=\"fabriqu&eacute; en france\" src=\"{{media url=\"wysiwyg/fabriqu_-en-france.jpg\"}}\" alt=\"fabriqu&eacute; en france\" />'\n",
      " '<span style=\"color:#2445a2;\">' \"<p align='justify'>\" '<blockquote>'\n",
      " '</blockquote>' '<big>' '<small>' '</small>' '</big>'\n",
      " '<a href=&quot;http://www.digitbooks.fr/catalogue/9782815001748.html&quot;>'\n",
      " '<br style=\"color: #ff0000;\" />'\n",
      " '<iframe height=\"315\" src=\"https://www.youtube.com/embed/omwhuchmals\" frameborder=\"0&quot;\" width=\"560\" allowfullscreen allow=\"autoplay; encrypted-media\">'\n",
      " \"<span style='text-decoration: underline;'>\"\n",
      " \"<iframe width='615' height='315' src='http://www.youtube.com/embed/z_ta-c0_vyi?autoplay=0' frameborder='0' allowfullscreen>\"\n",
      " '<a title=\"huile essentielle fleurs d\\'oranger\" href=\"http://www.piscine-distribution.com/bien-etre/aromatherapie-essences-pour-spa/huiles-essentielles-velours-de-spa/fleur-d-oranger-aromatherapie.html\">'\n",
      " '<a title=\"huile essentielle de lavandin\" href=\"http://www.piscine-distribution.com/bien-etre/aromatherapie-essences-pour-spa/huiles-essentielles-velours-de-spa/lavandin-aromatherapie.html\">'\n",
      " '<a title=\"huiles essentielles luxe\" href=\"http://www.piscine-distribution.com/bien-etre/aromatherapie-essences-pour-spa/huiles-essentielles-velours-de-spa/luxe-aromatherapie.html\">'\n",
      " '<a title=\"huiles essentielles eucalyptus menthe\" href=\"http://www.piscine-distribution.com/bien-etre/aromatherapie-essences-pour-spa/huiles-essentielles-velours-de-spa/eucalyptus-menthe-aromatherapie.html\">'\n",
      " '<a title=\"huiles essentielles d\\'asie\" href=\"http://www.piscine-distribution.com/bien-etre/aromatherapie-essences-pour-spa/huiles-essentielles-velours-de-spa/asie-aromatherapie.html\">'\n",
      " '<img style=\"display: block; margin-left: auto; margin-right: auto;\" title=\"aromath&eacute;rapie asie\" src=\"{{media url=\"wysiwyg/asie.png\"}}\" alt=\"aromath&eacute;rapie asie\" width=\"152\" height=\"154\" />'\n",
      " '<div style=\"text-align: left;\">' '<div style=\"text-align: center;\">'\n",
      " '<object width=\"850\" height=\"1000\" type=\"text/html\" data=\"http://194.185.40.5/area_informativa/ricerca_schede/schedehwserviziodati.asp?idazienda=1&codice=040141\">'\n",
      " '<a href=&quot;http://www.theatre.wf/france3.html&quot;>'\n",
      " \"<table cellspacing=''1'' cellpadding=''6'' style=''margin-left: 8px;'' id=''scheda_tecnica'' >\"\n",
      " \"<td class = ''title-tech'' colspan=''2''>\"\n",
      " \"<td style=''width: 5px;padding:0px''>\"\n",
      " \"<td valign=''top'' style=''width: 112px;font-weight:bold;''>\"\n",
      " \"<td valign=''top'' style=''width: 245px;''>\"\n",
      " \"<td valign=''top'' style=''width: 112px;font-weight:bold;'' >\"\n",
      " \"<td style=''width: 112px;font-weight:bold;''>\"\n",
      " \"<td style=''width: 245px''>\" \"<td colspan=''2''>\"\n",
      " '<span class=\"hps alt-edited\">' '<span style=font-size: small;>'\n",
      " '<a href=&quot;http://www.tierslivre.net/spip/spip.php?article769&quot;>'\n",
      " '<a href=&quot;http://www.tierslivre.net&quot;>'\n",
      " '<a href=&quot;http://www.editionsdelahutte.com/essais.html#histoiredieu&quot;>'\n",
      " '<a href=\"http://www.supreme.fr/pages/aramith.html\" class=\"colorbox\" colorbox-width=\"800\" colorbox-height=\"520\">'\n",
      " '<button class=\"form-button\">' '</button>' '<p align=\"center\">'\n",
      " '<img src=\"http://pmcdn.priceminister.com/photo/940782168.jpg\"  >'\n",
      " '<img src=\"http://pmcdn.priceminister.com/photo/940782173.jpg\"  >'\n",
      " '<img src=\"http://pmcdn.priceminister.com/photo/940782170.jpg\"  >'\n",
      " '<b style=&quot;font-weight:normal; font-style: italic;&quot;>'\n",
      " '<font size=\"3\">'\n",
      " '<img title=\"sryh\" src=\"http://www.piscine-distribution.com/media/wysiwyg/fleur-d-oranger.jpg\" alt=\"dsgh\" width=\"95\" height=\"103\" />'\n",
      " '<img title=\"velours de spa lavandin\" src=\"http://www.piscine-distribution.com/media/wysiwyg/lavandin.jpg\" alt=\"velours de spa lavandin\" width=\"105\" height=\"99\" />'\n",
      " '<img title=\"velours de spa luxe\" src=\"http://www.piscine-distribution.com/media/wysiwyg/luxe.jpg\" alt=\"velours de spa luxe\" width=\"115\" height=\"125\" />'\n",
      " '<img title=\"velours de spa eucalyptus menthe\" src=\"http://www.piscine-distribution.com/media/wysiwyg/eucalyptusfeuillesmenthe__0.jpg\" alt=\"velours de spa eucalyptus menthe\" width=\"104\" height=\"122\" />'\n",
      " '<a href=&quot;#9782814500556&quot; rel=&quot;bookmark&quot;>'\n",
      " '<a href=&quot;http://www.tierslivre.net&quot; rel=&quot;external&quot;>'\n",
      " '<a href=&quot;http://www.inventaire-invention.com/entretien/gibourg_rolin.htm&quot; rel=&quot;external&quot;>'\n",
      " '<a href=&quot;http://www.inventaire-invention.com/lectures/gibourg_agamben.htm&quot; rel=&quot;external&quot;>'\n",
      " '<span id=\"result_box\" class=\"\">' '<span class=\"\">'\n",
      " '<span lang=\"en\" tabindex=\"-1\">'\n",
      " '<span class=\"short_text\" id=\"result_box\" lang=\"en\" tabindex=\"-1\">'\n",
      " '<h3 style=\"text-align: left;\">'\n",
      " '<img style=\"display: block; margin-left: auto; margin-right: auto;\" title=\"huiles essentielles cajeput citron\" src=\"{{media url=\"wysiwyg/cajeput-citron.jpg\"}}\" alt=\"huiles essentielles cajeput citron\" width=\"116\" height=\"122\" />'\n",
      " '<img style=\"display: block; margin-left: auto; margin-right: auto;\" title=\"fabriqu&eacute; en france\" src=\"http://www.piscine-distribution.com/media/wysiwyg/fabriqu_-en-france.jpg\" alt=\"fabriqu&eacute; en france\" width=\"170\" height=\"170\" />'\n",
      " '<span style=\"text-decoration:underline;font-size:12pt;\">'\n",
      " '<span style=\"color:#ff0000;text-decoration:underline;\">'\n",
      " '<a href=\"http://piece-console.com/fr/431-pack-de-tournevis-torx-t-8-9-10-avec-t8-bit-securit-pour-les-vis-ps3-3760235651961.html\" target=\"_blank\">'\n",
      " '<a href=\"http://www.dealgame.org/technique/demonter_sa_ps3_slim_de_a_a_z_%5btuto%5d_298.html\" target=\"_blank\">'\n",
      " '<a href=\"http://www.ifixit.com/device/playstation_3_slim\" target=\"_blank\">'\n",
      " '<p align=justify>' '<font color=&quot;#000000&quot;>'\n",
      " '<font face=&quot;verdana&quot; size=&quot;2&quot; color=&quot;#660066&quot;>'\n",
      " '<object width=\"850\" height=\"1000\" type=\"text/html\" data=\"http://194.185.40.5/area_informativa/ricerca_schede/schedehwserviziodati.asp?idazienda=1&codice=570930\">'\n",
      " '<div class=\"mttextarea\" dir=\"ltr\" id=\"translationoutput\">'\n",
      " '<div class=\"force_dir\">'\n",
      " '<strong style=\"font-family: arial helvetica sans-serif; font-size: 8pt;\">'\n",
      " '<a rel=&quot;external&quot; href=&quot;http://www.tierslivre.net&quot;>'\n",
      " '<a href=&quot;http://www.publie.net/livre/blasons-dun-corps-masculin-regine-detambel/&quot;>'\n",
      " \"<span id='lbldescription'>\"\n",
      " \"<table class='desc-wrap' width='100%' border='0' cellspacing='0' cellpadding='0'>\"\n",
      " \"<td colspan='3' height='30'>\"\n",
      " \"<img src='http://cdn1.webvoo.com/cdn/common/spacer.gif' width='1' height='30' />\"\n",
      " \"<td valign='top'>\" \"<td width='45'>\"\n",
      " \"<img src='http://cdn1.webvoo.com/cdn/common/spacer.gif' width='45'height='1' />\"\n",
      " \"<img src='http://cdn1.webvoo.com/cdn/common/spacer.gif' width='1' height='50' />\"\n",
      " '<hr/>' \"<span style='text-align:center color: #7f7f7f font-size:11px '>\"\n",
      " \"<p align='right'>\" '<span style=\"text-decoration: underline;\">'\n",
      " '<span style=\"font-size: 11px;\">' '<span style=\"font-size: 8pt;\">'\n",
      " '<span id=\"spans0e0\" style=\"color:#0000ff;\">'\n",
      " '<a href=\"http://piece-console.com/blog/32-guide-de-reparation-tutoriel-de-demontage-manette-playstation-4\" target=\"_blank\">'\n",
      " '<p style=\"font-style: normal; font-size: 10.666666984558105px; font-family: verdana arial helvetica sans-serif;\">'\n",
      " '<a href=\"586\" \"\">'\n",
      " '<a href=&quot;http://remue.net/spip.php?article2350&quot; rel=&quot;external&quot;>'\n",
      " '<a href=&quot;http://www.sebastienrongier.net&quot; rel=&quot;external&quot;>'\n",
      " '<p style=text-align: justify;>'\n",
      " '<object width=\"850\" height=\"1000\" type=\"text/html\" data=\"http://194.185.40.5/area_informativa/ricerca_schede/schedehwserviziodati.asp?idazienda=1&codice=102854\">'\n",
      " '<strong style=\"color: #2e3c57;\">' '<strong style=\"color: #577300;\">'\n",
      " \"<!-- p.p1 margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'trebuchet ms'; color: #000000; -webkit-text-stroke: #000000 p.p2 margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'trebuchet ms'; color: #000000; -webkit-text-stroke: #000000; min-height: 14.0px p.p3 margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'trebuchet ms'; color: #ff0000; -webkit-text-stroke: #ff0000 li.li1 margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'trebuchet ms'; color: #000000; -webkit-text-stroke: #000000 span.s1 font-kerning: none span.s2 font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000 span.s3 font: 12.0px helvetica; color: #000000 -->\"\n",
      " '<span style=\"font-family: verdanaarialhelveticagenevaswisssunsans-regular; font-size: 8pt;\" data-mce-style=\"font-family: verdanaarialhelveticagenevaswisssunsans-regular; font-size: 8pt;\">'\n",
      " '<span style=\"font-style: normal; font-size: 10.666666984558105px; font-family: verdana arial helvetica sans-serif;\">'\n",
      " \"<a href='http://www.annabac.com'>\"\n",
      " '<span style=\"font-family: verdana; font-size: 14pt;\">'\n",
      " '<div align=\"center\">'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i2/119219540/tb2htc3l3xlpufjsszgxxcjdpxa_!!119219540.jpg\" alt=\" e0405d1 ??? (1).jpg\" />'\n",
      " '<span style=\"font-family: verdana; font-size: 14pt; color: red;\">'\n",
      " '<br style=\"font-family: verdana; font-size: 14pt;\" />'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i3/2788558980/tb2dcwdxy.b61bjy0fnxxaepxxa_%21%212788558980.jpg\" alt=\" (6).jpg\" />'\n",
      " '<div id=\"pastingspan1\">'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i4/2788558980/tb2gms3ahwb61bjszjixxbd3xxa_!!2788558980.jpg\" alt=\" 1(1).jpg\" />'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i3/2788558980/tb2pysgx4wa61bjsspexxxx9fxa_!!2788558980.jpg\" alt=\" (2).jpg\" />'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i4/2788558980/tb241eexzga61bjy1xaxxafzvxa_!!2788558980.jpg\" alt=\" (3).jpg\" />'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i1/2788558980/tb290hhacgd61bjszfpxxcasvxa_%21%212788558980.jpg\" alt=\" (8).jpg\" />'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i1/2788558980/tb2hdjiahab61bjszfbxxc9pfxa_%21%212788558980.jpg\" alt=\" (9).jpg\" />'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i3/2788558980/tb2l6zzxzsx61bjy1xdxxa0afxa_!!2788558980.jpg\" alt=\" (5).jpg\" />'\n",
      " '<img src=\"https://img.alicdn.com/imgextra/i4/2788558980/tb2wvzfxzwx61bjsspaxxxlrpxa_!!2788558980.jpg\" alt=\" (4).jpg\" />'\n",
      " '<div class=fiche_produit>' '<div style=clear: both>'\n",
      " '<span style=\"font-weight: bold;\">'\n",
      " '<iframe src=http://player.vimeo.com/video/36480591 width=400 height=225 frameborder=0 webkitallowfullscreen mozallowfullscreen allowfullscreen>'\n",
      " '<a href=http://vimeo.com/36480591>'\n",
      " '<a href=http://vimeo.com/clockwork>' '<a href=http://vimeo.com>'\n",
      " '<a href=&quot;http://lasagademo.publie.net&quot;>'\n",
      " \"<font color='#cc0000'>\" '<strong/>' '<span class=\"alt-edited\">' '<lt/>'\n",
      " '<gt/>' '<center>'\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-1.jpg' alt='warhammer-et-vermintidedrachenfels-1' />\"\n",
      " '</center>'\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-2.jpg' alt='warhammer-et-vermintidedrachenfels-2' />\"\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-3.jpg' alt='warhammer-et-vermintidedrachenfels-3' />\"\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-4.jpg' alt='warhammer-et-vermintidedrachenfels-4' />\"\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-5.jpg' alt='warhammer-et-vermintidedrachenfels-5' />\"\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-6.jpg' alt='warhammer-et-vermintidedrachenfels-6' />\"\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-7.jpg' alt='warhammer-et-vermintidedrachenfels-7' />\"\n",
      " \"<img style='max-width: 100%;' src='https://www.telechargement.fr/images/products/fatshark/fatshark-warhammer-et-vermintidedrachenfels-8.jpg' alt='warhammer-et-vermintidedrachenfels-8' />\"\n",
      " '<a href=&quot;http://www.textesgais.fr/&quot;>' '<span class=\"text1\">'\n",
      " '<a href=&quot;http://www.culturecommune.com/&quot;>']\n"
     ]
    }
   ],
   "source": [
    "balises = df['description'].apply(lambda x: re.findall(r'<.*?>', str(x)))\n",
    "print(balises.explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les balise html\n",
    "df['description'] = df['description'].apply(lambda x: re.sub(r'<.*?>', '', str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "balises = df['description'].apply(lambda x: re.findall(r'<.*?>', str(x)))\n",
    "print(balises.explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer \"&eacute;\" et \"nan\"\n",
    "df[\"description\"] = df[\"description\"].apply(\n",
    "    lambda x: re.sub(r\"&eacute;|nan|&#39;|&amp;|nbsp;\", \"\", str(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "df['description'] = df['description'].apply(lambda x: emoji_pattern.sub('', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supprimer les mots en double\n",
    "df['description'] = df['description'].apply(lambda x: ' '.join(sorted(set(x.split()), key=x.split().index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les mots vides\n",
    "df['description'] = df['description'].apply(lambda x: ' '.join(sorted(set(x.split()), key=x.split().index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les mots courts\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_shortwords(texte):\n",
    "    words = texte.split()\n",
    "    filter_words = [word for word in words if len(word) > 2] \n",
    "    return ' '.join(filter_words)\n",
    "\n",
    "df['description'] = df['description'].apply(remove_shortwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/guimb/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/guimb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Appliquer la lemmatisation\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fonction de lemmatisation\n",
    "def lemmatisation(texte):\n",
    "    mots = texte.split()\n",
    "    lemmatized = [lemmatizer.lemmatize(mot) for mot in mots]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "df['description'] = df['description'].apply(lemmatisation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialiser la variable des mots vides\n",
    "stop_words = set(stopwords.words('french'))\n",
    "stop_words.update([\",\", \".\"])\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filter_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filter_words)\n",
    "\n",
    "df['description'] = df['description'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.description, df.prdtypecode\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVC: 100%|██████████| 100/100 [00:31<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: Accuracy = 0.586\n",
      "\n",
      "Training LinearSVC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LinearSVC: 100%|██████████| 100/100 [00:00<00:00, 121.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC: Accuracy = 0.629\n",
      "\n",
      "Training LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 100%|██████████| 100/100 [00:05<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Accuracy = 0.622\n",
      "\n",
      "Training SGDClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SGDClassifier: 100%|██████████| 100/100 [00:05<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier: Accuracy = 0.601\n",
      "\n",
      "Training MLPClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MLPClassifier:   0%|          | 0/100 [00:00<?, ?it/s]/Users/guimb/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "MLPClassifier: 100%|██████████| 100/100 [00:04<00:00, 23.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier: Accuracy = 0.378\n",
      "\n",
      "Training KNeighborsClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier: 100%|██████████| 100/100 [00:00<00:00, 182.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier: Accuracy = 0.521\n",
      "\n",
      "Training RandomForestClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: 100%|██████████| 100/100 [00:00<00:00, 266.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: Accuracy = 0.291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Réduction de la taille de l'échantillon\n",
    "sample_size = 1000\n",
    "\n",
    "\n",
    "# Utilisation d'un sous-ensemble de l'échantillon\n",
    "X_train = X_train.sample(sample_size, random_state=42)\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "X_test = X_test.sample(sample_size, random_state=42)\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Vectorisation des descriptions\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Liste des modèles avec leurs paramètres\n",
    "models = [\n",
    "    (\"SVC\", SVC(C=10, kernel=\"linear\")),\n",
    "    (\"LinearSVC\", LinearSVC(dual=False, penalty=\"l2\")),\n",
    "    (\"LogisticRegression\", LogisticRegression(class_weight=\"balanced\", max_iter=200)),\n",
    "    (\"SGDClassifier\", SGDClassifier(penalty=\"l2\")),\n",
    "    (\"KNeighborsClassifier\", KNeighborsClassifier(metric=\"minkowski\", n_neighbors=4)),\n",
    "    (\n",
    "        \"RandomForestClassifier\",\n",
    "        RandomForestClassifier(criterion=\"entropy\", max_depth=5),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Entraînement et évaluation des modèles avec barre de progression\n",
    "for model_name, model in models:\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "\n",
    "    X_train_dense = X_train_vec.toarray()\n",
    "    X_test_dense = X_test_vec.toarray()\n",
    "\n",
    "\n",
    "    # Utilisation de tqdm pour suivre l'avancement en pourcentage\n",
    "    with tqdm(total=100, desc=f\"{model_name}\", position=0, leave=True) as pbar:\n",
    "        model.fit(X_train_dense, y_train)\n",
    "        pbar.update(\n",
    "            50\n",
    "        )  # Mise à jour de la barre de progression à 50% (entraînement à 50%)\n",
    "\n",
    "        y_pred = model.predict(X_test_dense)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        pbar.update(\n",
    "            50\n",
    "        )  # Mise à jour de la barre de progression à 100% (évaluation à 50%)\n",
    "\n",
    "    print(f\"{model_name}: Accuracy = {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Evaluating SVC...\n",
      "SVC: Accuracy = 0.8073278584965256\n",
      "\n",
      "Training LinearSVC...\n",
      "Evaluating LinearSVC...\n",
      "LinearSVC: Accuracy = 0.8158559696778269\n",
      "\n",
      "Training LogisticRegression...\n",
      "Evaluating LogisticRegression...\n",
      "LogisticRegression: Accuracy = 0.7887976416087598\n",
      "\n",
      "Training SGDClassifier...\n",
      "Evaluating SGDClassifier...\n",
      "SGDClassifier: Accuracy = 0.7989050326384503\n",
      "\n",
      "Training MLPClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guimb/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier...\n",
      "MLPClassifier: Accuracy = 0.7910086333965045\n",
      "\n",
      "Training KNeighborsClassifier...\n",
      "Evaluating KNeighborsClassifier...\n",
      "KNeighborsClassifier: Accuracy = 0.3432301537165719\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "Evaluating RandomForestClassifier...\n",
      "RandomForestClassifier: Accuracy = 0.24236681406611918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prétraitement des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"description\"], df[\"prdtypecode\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorisation des descriptions\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Liste des modèles avec leurs paramètres\n",
    "models = [\n",
    "    (\"SVC\", SVC(C=10, kernel=\"linear\")),\n",
    "    (\"LinearSVC\", LinearSVC(dual=False, penalty=\"l2\")),\n",
    "    (\"LogisticRegression\", LogisticRegression(class_weight=\"balanced\", max_iter=200)),\n",
    "    (\"SGDClassifier\", SGDClassifier(penalty=\"l2\")),\n",
    "    (\"MLPClassifier\", MLPClassifier(hidden_layer_sizes=(10,), max_iter=40)),\n",
    "    (\"KNeighborsClassifier\", KNeighborsClassifier(metric=\"minkowski\", n_neighbors=4)),\n",
    "    (\n",
    "        \"RandomForestClassifier\",\n",
    "        RandomForestClassifier(criterion=\"entropy\", max_depth=5),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Entraînement et évaluation des modèles avec barre de progression\n",
    "for model_name, model in models:\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name}: Accuracy = {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_RF = vectorizer.fit_transform(X_train)\n",
    "X_test_RF = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_RF = RandomForestClassifier()\n",
    "clf_RF.fit(X_train_RF,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = clf_RF.predict(X_test_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.50      0.12      0.20         8\n",
      "          40       1.00      0.08      0.15        12\n",
      "          50       0.88      0.29      0.44        24\n",
      "          60       0.77      0.77      0.77        13\n",
      "        1140       0.53      0.77      0.62        13\n",
      "        1160       1.00      0.67      0.80         6\n",
      "        1180       0.00      0.00      0.00         5\n",
      "        1280       0.40      0.47      0.43        77\n",
      "        1281       0.32      0.24      0.27        29\n",
      "        1300       0.65      0.86      0.74        69\n",
      "        1301       1.00      0.23      0.38        13\n",
      "        1302       0.08      0.28      0.12        53\n",
      "        1320       1.00      0.15      0.26        47\n",
      "        1560       0.49      0.48      0.49        97\n",
      "        1920       0.83      0.78      0.80        63\n",
      "        1940       1.00      0.25      0.40        16\n",
      "        2060       0.40      0.62      0.49        80\n",
      "        2220       1.00      0.17      0.29        12\n",
      "        2280       0.00      0.00      0.00         7\n",
      "        2403       0.00      0.00      0.00         1\n",
      "        2462       0.00      0.00      0.00         2\n",
      "        2522       0.80      0.30      0.43        54\n",
      "        2582       0.35      0.14      0.20        51\n",
      "        2583       0.73      0.81      0.77       144\n",
      "        2585       0.58      0.22      0.32        50\n",
      "        2705       0.83      0.63      0.72        30\n",
      "        2905       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.50      1000\n",
      "   macro avg       0.60      0.38      0.41      1000\n",
      "weighted avg       0.61      0.50      0.50      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guimb/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/guimb/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/guimb/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calcul du rapport de classification\n",
    "classification_rep = classification_report(y_test, y_pred_RF)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guimb/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2088/2088 [==============================] - 997s 477ms/step - loss: 1.5233 - accuracy: 0.5434 - val_loss: 0.9099 - val_accuracy: 0.7275\n",
      "Epoch 2/10\n",
      "2088/2088 [==============================] - 1089s 521ms/step - loss: 0.6267 - accuracy: 0.8097 - val_loss: 0.7495 - val_accuracy: 0.7796\n",
      "Epoch 3/10\n",
      "2088/2088 [==============================] - 1121s 537ms/step - loss: 0.3067 - accuracy: 0.9077 - val_loss: 0.7634 - val_accuracy: 0.7849\n",
      "Epoch 4/10\n",
      "2088/2088 [==============================] - 1149s 550ms/step - loss: 0.1629 - accuracy: 0.9510 - val_loss: 0.8151 - val_accuracy: 0.7931\n",
      "Epoch 5/10\n",
      "2088/2088 [==============================] - 1480s 709ms/step - loss: 0.0933 - accuracy: 0.9720 - val_loss: 0.9231 - val_accuracy: 0.7847\n",
      "Epoch 6/10\n",
      "2088/2088 [==============================] - 1205s 577ms/step - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.9908 - val_accuracy: 0.7893\n",
      "Epoch 7/10\n",
      "2088/2088 [==============================] - 1257s 602ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 1.0800 - val_accuracy: 0.7843\n",
      "Epoch 8/10\n",
      "2088/2088 [==============================] - 1148s 550ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 1.1137 - val_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "2088/2088 [==============================] - 1079s 517ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 1.1468 - val_accuracy: 0.7872\n",
      "Epoch 10/10\n",
      "2088/2088 [==============================] - 1179s 565ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.2533 - val_accuracy: 0.7833\n",
      "522/522 [==============================] - 52s 100ms/step - loss: 1.2533 - accuracy: 0.7833\n",
      "Loss: 1.2532942295074463, Accuracy: 0.7832804322242737\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Prétraitement des données\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df[\"description\"])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(df[\"description\"])\n",
    "padded_sequences = pad_sequences(input_sequences)\n",
    "\n",
    "# Encodage des étiquettes\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df[\"prdtypecode\"])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# Construction du modèle\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=len(padded_sequences[0])))\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dense(onehot_encoded.shape[1], activation=\"softmax\"))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    padded_sequences, onehot_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "# Prédictions sur de nouvelles données\n",
    "# Remplacez 'nouvelles_sequences' par les séquences de texte de vos nouvelles données\n",
    "nouvelles_sequences = tokenizer.texts_to_sequences(\"Peluche Bob l'éponge\")\n",
    "nouvelles_padded_sequences = pad_sequences(\n",
    "    nouvelles_sequences, maxlen=len(padded_sequences[0])\n",
    ")\n",
    "\n",
    "predictions = model.predict(nouvelles_padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur de nouvelles données\n",
    "# Remplacez 'nouvelles_sequences' par les séquences de texte de vos nouvelles données\n",
    "nouvelles_sequences = tokenizer.texts_to_sequences(\"Peluche Bob l'éponge\")\n",
    "nouvelles_padded_sequences = pad_sequences(\n",
    "    nouvelles_sequences, maxlen=len(padded_sequences[0])\n",
    ")\n",
    "\n",
    "predictions = model.predict(nouvelles_padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/guimb/Documents/Data Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Embedding, GRU, Dense\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guimb/Documents/Data%20Scientest/rakuten/Git/AUG23_Rakuten/notebooks/modelisation.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m Tokenizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Prétraitement des données\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df[\"description\"])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(df[\"description\"])\n",
    "padded_sequences = pad_sequences(input_sequences)\n",
    "\n",
    "# Encodage des étiquettes\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df[\"prdtypecode\"])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    padded_sequences, onehot_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Construction du modèle avec une couche GRU\n",
    "embedding_dim = 100\n",
    "gru_units = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, embedding_dim))\n",
    "model.add(GRU(gru_units, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(onehot_encoded.shape[1], activation=\"softmax\"))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakuten_tooling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
